{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRfoypabgr9oNl32bBHNMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RomanKunal/Deep-Learning/blob/main/NLP_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEXT PREPROCESSING\n",
        "1. LowerCasing\n",
        "2. Remove HTML Tags\n",
        "3. Remove URLs\n",
        "4. Remove Punctuation\n",
        "5. Chatword Removal\n",
        "6. Spelling Correction\n",
        "7. Removing stop words\n",
        "8. Handling Emojis\n",
        "9. Tokenization"
      ],
      "metadata": {
        "id": "VOCDB3IidrdC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_f2s_GF6O-HI",
        "outputId": "2b2e1ec4-bc58-48ee-b72a-04882ce5f01d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the gentle breeze swirled through the trees, rustling the leaves. birds chirped in harmony as the sun set, casting soft shadows over the quiet, peaceful landscape. everything felt serene and timeless.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "text='The gentle breeze swirled through the trees, rustling the leaves. Birds chirped in harmony as the sun set, casting soft shadows over the quiet, peaceful landscape. Everything felt serene and timeless.'\n",
        "text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Html Tags\n",
        "text='<p>The <strong>sun</strong> rises over the horizon, casting a <em>golden</em> glow. <a href=\"#\">Nature</a> awakens, and birds begin to <u>sing</u> in the early morning light.</p>'\n",
        "import re\n",
        "def removal_html_tags(text):\n",
        "  pattern=re.compile('<.*?>')\n",
        "  return pattern.sub(r'',text)\n",
        "removal_html_tags(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hLxiB2R_exjp",
        "outputId": "206ffe3b-0a29-4415-baec-3e87033e500e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The sun rises over the horizon, casting a golden glow. Nature awakens, and birds begin to sing in the early morning light.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing urls\n",
        "text='For learning programming, visit https://www.w3schools.com for tutorials on HTML, CSS, and JavaScript'\n",
        "def remove_url(text):\n",
        "  url=re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return url.sub(r'',text)\n",
        "remove_url(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RKcQP1PmkzTQ",
        "outputId": "1f83f95f-59b1-4dd5-f1e1-856f0a5630ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For learning programming, visit  for tutorials on HTML, CSS, and JavaScript'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Punctuations\n",
        "import string\n",
        "string.punctuation\n",
        "\n",
        "def remove_pun(text):\n",
        "  for pun in string.punctuation:\n",
        "    text=text.replace(pun,'')\n",
        "  return text\n",
        "remove_pun(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1m_g54_iopnw",
        "outputId": "5dcba191-dbd9-48f3-8260-15ca697ae2fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For learning programming visit httpswwww3schoolscom for tutorials on HTML CSS and JavaScript'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ChatWord Removal\n",
        "chat_words={\n",
        "    'AFAIK':'As Far As I Know',\n",
        "    'AFK':'Away From Keyboard',\n",
        "    'ASAP':'As Soon As Possible',\n",
        "    'ATK':'At The Keyboard',\n",
        "    'ATM':'At The Moment'}\n",
        "\n",
        "def remove_chat_words(text):\n",
        "  new_text=[]\n",
        "  for word in text.split():\n",
        "    if word.upper() in chat_words:\n",
        "      new_text.append(chat_words[word.upper()])\n",
        "    else:\n",
        "      new_text.append(word)\n",
        "  return \" \".join(new_text)\n",
        "text='Asap i need my shoes'\n",
        "remove_chat_words(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XnuMkXqUpaNU",
        "outputId": "647ff83e-d03d-4df5-d280-a5906b15e99f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As Soon As Possible i need my shoes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Spelling correction\n",
        "incorrext_text='ceertain new thingggs are theere'\n",
        "from textblob import TextBlob\n",
        "def correct_spelling(text):\n",
        "  return str(TextBlob(text).correct())\n",
        "correct_spelling(incorrext_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F-OHDLOiqEmG",
        "outputId": "0360cfc4-2404-43b0-ca2e-8a6f37860cf1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'certain new things are there'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling Emojis\n",
        "!pip install emoji\n",
        "import emoji\n",
        "print(emoji.demojize('Python is üëç'))\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmTUSKsTrTgU",
        "outputId": "1ed1d7e5-bf74-40bc-b788-f6c7cbfb2187"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.0\n",
            "Python is :thumbs_up:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stop Words Removal\n",
        "import spacy\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example text\n",
        "text = \"For learning programming, visit https://www.w3schools.com for tutorials on HTML, CSS, and JavaScript.\"\n",
        "\n",
        "# Process the text using spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Remove stop words\n",
        "filtered_tokens = []\n",
        "\n",
        "for token in doc:\n",
        "    if not token.is_stop and not token.is_punct:\n",
        "        filtered_tokens.append(token.text)\n",
        "\n",
        "\n",
        "# Join the tokens back into a sentence\n",
        "filtered_text = \" \".join(filtered_tokens)\n",
        "\n",
        "print(\"Original Text:\", text)\n",
        "print(\"Filtered Text:\", filtered_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na_6cWfyugHw",
        "outputId": "7fbb7c69-cef5-4692-c971-dd1c2b5ce246"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: For learning programming, visit https://www.w3schools.com for tutorials on HTML, CSS, and JavaScript.\n",
            "Filtered Text: learning programming visit https://www.w3schools.com tutorials HTML CSS JavaScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "doc=nlp(text)\n",
        "for token in doc:\n",
        "  print(token)\n",
        "\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAJa-eudspM-",
        "outputId": "12ce2b89-bacd-4f8d-ea3e-f22c20b3bf14"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My\n",
            "name\n",
            "is\n",
            "blah\n",
            "blah\n",
            "and\n",
            "for\n",
            "sure\n",
            "i\n",
            "want\n",
            "idk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming\n",
        "import spacy\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize Porter Stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Example text\n",
        "text = \"running runners flies flying studied studying\"\n",
        "\n",
        "# Process text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Perform stemming using Porter Stemmer\n",
        "stems = [stemmer.stem(token.text) for token in doc]\n",
        "\n",
        "# Print results\n",
        "print(\"Original Words:\", [token.text for token in doc])\n",
        "print(\"Stemmed Words:\", stems)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN8ysqIIw7BH",
        "outputId": "082cc4fc-384e-44ec-fd29-83ae503462bf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Words: ['running', 'runners', 'flies', 'flying', 'studied', 'studying']\n",
            "Stemmed Words: ['run', 'runner', 'fli', 'fli', 'studi', 'studi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bag of Words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "text='My name is Kunal and i do gym hehehe'\n",
        "cv=CountVectorizer()\n",
        "bag_of_words=cv.fit_transform([text])\n",
        "print(cv.vocabulary_)\n",
        "print(bag_of_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m55Ul7G0xAEb",
        "outputId": "6b853d53-5997-4dbf-90b3-85a1f769482b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'my': 6, 'name': 7, 'is': 4, 'kunal': 5, 'and': 0, 'do': 1, 'gym': 2, 'hehehe': 3}\n",
            "  (0, 6)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 5)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 1)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 3)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Example documents\n",
        "documents = [\n",
        "    \"Natural Language Processing is fun and exciting.\",\n",
        "    \"I love learning about Natural Language Processing.\",\n",
        "    \"Text mining and NLP techniques are powerful tools.\"\n",
        "]\n",
        "\n",
        "# Create the TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the documents to compute the TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Convert the result to a dense matrix (optional)\n",
        "dense_matrix = tfidf_matrix.todense()\n",
        "\n",
        "# Get the feature names (words)\n",
        "words = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print TF-IDF values for each document\n",
        "print(\"TF-IDF Matrix (Dense Representation):\")\n",
        "print(dense_matrix)\n",
        "\n",
        "# Print words corresponding to the columns of the TF-IDF matrix\n",
        "print(\"\\nWords in the TF-IDF Matrix:\", words)\n",
        "\n",
        "# Display TF-IDF for each word in each document\n",
        "for i, doc in enumerate(dense_matrix):\n",
        "    print(f\"\\nDocument {i+1} TF-IDF Scores:\")\n",
        "    for j, word in enumerate(words):\n",
        "        print(f\"{word}: {doc[0, j]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhxZDt5-3Iv3",
        "outputId": "2aed1883-1189-4db0-887b-d57fd4c0872b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix (Dense Representation):\n",
            "[[0.         0.32992832 0.         0.43381609 0.43381609 0.43381609\n",
            "  0.32992832 0.         0.         0.         0.32992832 0.\n",
            "  0.         0.32992832 0.         0.         0.        ]\n",
            " [0.45954803 0.         0.         0.         0.         0.\n",
            "  0.34949812 0.45954803 0.45954803 0.         0.34949812 0.\n",
            "  0.         0.34949812 0.         0.         0.        ]\n",
            " [0.         0.27626457 0.36325471 0.         0.         0.\n",
            "  0.         0.         0.         0.36325471 0.         0.36325471\n",
            "  0.36325471 0.         0.36325471 0.36325471 0.36325471]]\n",
            "\n",
            "Words in the TF-IDF Matrix: ['about' 'and' 'are' 'exciting' 'fun' 'is' 'language' 'learning' 'love'\n",
            " 'mining' 'natural' 'nlp' 'powerful' 'processing' 'techniques' 'text'\n",
            " 'tools']\n",
            "\n",
            "Document 1 TF-IDF Scores:\n",
            "about: 0.0000\n",
            "and: 0.3299\n",
            "are: 0.0000\n",
            "exciting: 0.4338\n",
            "fun: 0.4338\n",
            "is: 0.4338\n",
            "language: 0.3299\n",
            "learning: 0.0000\n",
            "love: 0.0000\n",
            "mining: 0.0000\n",
            "natural: 0.3299\n",
            "nlp: 0.0000\n",
            "powerful: 0.0000\n",
            "processing: 0.3299\n",
            "techniques: 0.0000\n",
            "text: 0.0000\n",
            "tools: 0.0000\n",
            "\n",
            "Document 2 TF-IDF Scores:\n",
            "about: 0.4595\n",
            "and: 0.0000\n",
            "are: 0.0000\n",
            "exciting: 0.0000\n",
            "fun: 0.0000\n",
            "is: 0.0000\n",
            "language: 0.3495\n",
            "learning: 0.4595\n",
            "love: 0.4595\n",
            "mining: 0.0000\n",
            "natural: 0.3495\n",
            "nlp: 0.0000\n",
            "powerful: 0.0000\n",
            "processing: 0.3495\n",
            "techniques: 0.0000\n",
            "text: 0.0000\n",
            "tools: 0.0000\n",
            "\n",
            "Document 3 TF-IDF Scores:\n",
            "about: 0.0000\n",
            "and: 0.2763\n",
            "are: 0.3633\n",
            "exciting: 0.0000\n",
            "fun: 0.0000\n",
            "is: 0.0000\n",
            "language: 0.0000\n",
            "learning: 0.0000\n",
            "love: 0.0000\n",
            "mining: 0.3633\n",
            "natural: 0.0000\n",
            "nlp: 0.3633\n",
            "powerful: 0.3633\n",
            "processing: 0.0000\n",
            "techniques: 0.3633\n",
            "text: 0.3633\n",
            "tools: 0.3633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word2Vec\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Sample corpus (list of tokenized sentences)\n",
        "sentences = [\n",
        "    ['dog', 'barks'],\n",
        "    ['cat', 'meows'],\n",
        "    ['dog', 'chases', 'cat'],\n",
        "    ['cat', 'climbs', 'tree'],\n",
        "]\n",
        "\n",
        "# Train a Word2Vec model\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Get the vector representation for the word 'dog'\n",
        "dog_vector = model.wv['dog']\n",
        "print(\"Vector for 'dog':\", dog_vector)\n",
        "\n",
        "# Find similar words to 'dog'\n",
        "similar_words = model.wv.most_similar('dog', topn=3)\n",
        "print(\"Words similar to 'dog':\", similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv6ERTWu4Z6s",
        "outputId": "e401b3c9-b5d0-4cac-978a-3177633933d0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'dog': [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
            "Words similar to 'dog': [('climbs', 0.06797593832015991), ('meows', 0.0093911774456501), ('chases', 0.0045030200853943825)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part of speech tagging\n",
        "import spacy\n",
        "\n",
        "# Load the SpaCy model for English\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Process the text using SpaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterate over the tokens and print the word along with its POS tag\n",
        "for token in doc:\n",
        "    print(f\"Word: {token.text}, POS: {token.pos_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg6ehff37Idb",
        "outputId": "582c78af-e676-43dd-a01f-1077a567ddf2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: The, POS: DET\n",
            "Word: quick, POS: ADJ\n",
            "Word: brown, POS: ADJ\n",
            "Word: fox, POS: NOUN\n",
            "Word: jumps, POS: VERB\n",
            "Word: over, POS: ADP\n",
            "Word: the, POS: DET\n",
            "Word: lazy, POS: ADJ\n",
            "Word: dog, POS: NOUN\n",
            "Word: ., POS: PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NER\n",
        "import spacy\n",
        "\n",
        "# Load the pre-trained English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text\n",
        "text = \"Apple Inc. is looking to acquire a startup in Berlin for $2 billion. Tim Cook announced the plans last week.\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print the entities found in the text\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAofN6FS8WEu",
        "outputId": "1d29337e-33ef-40e0-f99f-02cd7104016a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Apple Inc., Label: ORG\n",
            "Entity: Berlin, Label: GPE\n",
            "Entity: $2 billion, Label: MONEY\n",
            "Entity: Tim Cook, Label: PERSON\n",
            "Entity: last week, Label: DATE\n"
          ]
        }
      ]
    }
  ]
}